{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from datetime import date, datetime, timedelta\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Entering the search query, from and to date - to get the news articles in that period"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2020-01-01\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def getQuery(str):\n",
    "    result = str.split()\n",
    "    return result\n",
    "query = getQuery('citizenship amendment bill india')\n",
    "# print(query)\n",
    "start = date(2020, 1, 1)\n",
    "end = date(2020, 1, 2)\n",
    "print(start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# creating a function for getting a url\n",
    "def createUrl(query, month, day, year):\n",
    "    tempQ = []\n",
    "    len_a = len(query)\n",
    "    if (len_a > 1):\n",
    "        for i in range(len_a):\n",
    "            tempQ.append(query[i])        \n",
    "        \n",
    "        sep = '+'\n",
    "        tempQ1 = sep.join(tempQ)\n",
    "        url = 'https://www.google.com/search?q=' + str(tempQ1) + '&sxsrf=ACYBGNTwLQ0U4gEoAyzjmWThzJK06MJhxw%3A1577815826486&source=lnt&tbs=cdr%3A1%2Ccd_min%3A' + str(month) + '%2F' + str(day) + '%2F' + str(year) + '%2Ccd_max%3A' + str(month) + '%2F' + str(day) + '%2F' + str(year) + '&tbm=nws'\n",
    "    \n",
    "    else:\n",
    "        url = 'https://www.google.com/search?q=' + str(query) + '&sxsrf=ACYBGNTwLQ0U4gEoAyzjmWThzJK06MJhxw%3A1577815826486&source=lnt&tbs=cdr%3A1%2Ccd_min%3A' + str(month) + '%2F' + str(day) + '%2F' + str(year) + '%2Ccd_max%3A' + str(month) + '%2F' + str(day) + '%2F' + str(year) + '&tbm=nws'\n",
    "        \n",
    "    return url\n",
    "\n",
    "# curl = createUrl(query, month=12, day=31, year=2019)\n",
    "# curl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<generator object dateRange at 0x7ff2a0d47fc0>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# defininig a function for getting a range of dates\n",
    "def dateRange(start, end):\n",
    "    temp = (end - start).days\n",
    "    # print(temp)\n",
    "    for i in range(int(temp)):\n",
    "        yield (start + timedelta(i))\n",
    "\n",
    "print(dateRange(start, end))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# function for getting the headlines using urllib and Beautiful Soup\n",
    "def captureHeadlines(page):\n",
    "    \n",
    "    # A user agent is string that each web browser sends to the website. It contains info.\n",
    "    # like the device software, OS, etc. so that the remote web servers use this data\n",
    "    # to optimize the webpage's performance and display.\n",
    "    userAgent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3579.0 Safari/537.36'\n",
    "    \n",
    "    headers = {\"User-Agent\": userAgent}\n",
    "    response = requests.get(page, headers = headers)\n",
    "    # print(response.content)\n",
    "    \n",
    "    pubList = ['The Guardian', 'The Independent', 'The New York Times', 'Vox' \n",
    "               'Bloomberg', 'The Atlantic', 'USA TODAY', 'Sky Sports', 'Verge', \n",
    "               'New Yorker', 'Forbes', 'Nature', 'CNN', 'CNBC', 'BBC News', 'NBC', \n",
    "               'Times of India', 'Hindu', 'Economic Times', 'Washington Post',\n",
    "               'Huffington Post', 'ESPN', 'The Indian Express',\n",
    "               'Hindustan Times', 'Foreign Policy']\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    headlinesCollec = []\n",
    "    # hdls = soup.find_all('div', attrs={'class': 'bkWMgd'})\n",
    "    # hdls1 = soup.find_all('div', attrs={'class': 'dbsr'})\n",
    "    hdls1 = soup.find_all('div', attrs={'class': 'gG0TJc'})\n",
    "    for data in hdls1:\n",
    "        print('\\n')\n",
    "        temp = data.find('a')\n",
    "        pub = data.find('span', attrs={'class': 'xQ82C'}).get_text()\n",
    "\n",
    "        # dataObj = {\n",
    "        #     \"Title\": data.find('div', attrs={'class': 'phYMDf nDgy9d'}).get_text(),\n",
    "        #     \"Publisher\": data.find('div', attrs={'class': 'pDavDe RGRr8e'}).get_text(),\n",
    "        #     \"Link\": temp['href']\n",
    "        # }\n",
    "        dataObj = {\n",
    "            \"Title\": data.find('h3', attrs={'class': 'r dO0Ag'}).get_text(),\n",
    "            \"Publisher\": pub,\n",
    "            \"Link\": temp['href']\n",
    "        }        \n",
    "        # another condition to get news only from major news sources\n",
    "        if (any(pub in j for j in pubList)):\n",
    "            headlinesCollec.append(dataObj)            \n",
    "    return headlinesCollec  \n",
    "    \n",
    "    # hdls1 = soup.find_all('div', attrs={'class': 'gG0TJc'})\n",
    "    # for data in hdls1:\n",
    "    #     print('\\n')\n",
    "    #     temp = data.find('a')\n",
    "    #     # print(temp)\n",
    "    #     pub = data.select('.slp .xQ82C')\n",
    "    #     # pubs = pub.select('.xQ82C')\n",
    "    #     print(len(pub))\n",
    "    #     title = data.select('r dO0Ag a')\n",
    "    #     # titles = title.select('.a')\n",
    "    #     print(len(title))\n",
    "    #     dataObj = {\n",
    "    #         \"Title\": title.get_text(),\n",
    "    #         \"Publisher\": pub.get_text(),\n",
    "    #         \"Link\": title['href']\n",
    "    #         }        \n",
    "    #         # another condition to get news only from major news sources\n",
    "    #     if (any(pub in j for j in pubList)):\n",
    "    #         headlinesCollec.append(dataObj)            \n",
    "    # return headlinesCollec  \n",
    "\n",
    "\n",
    "# captureHeadlines('https://www.google.com/search?q=arsenal&biw=1366&bih=669&sxsrf=ACYBGNTLcO_bWTajN0YjR_4rxoHl9GVo7g%3A1577820127297&source=lnt&tbs=cdr%3A1%2Ccd_min%3A12%2F29%2F2019%2Ccd_max%3A12%2F30%2F2019&tbm=nws')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def getHeadlines(query, start, end):\n",
    "    \n",
    "    urlList = []\n",
    "    for dates in dateRange(start,end):\n",
    "        # print(dates)\n",
    "        currentDate = dates.strftime(\"%m-%d-%Y\").split('-')\n",
    "        # print(currentDate)\n",
    "        url = createUrl(query, currentDate[0], currentDate[1], currentDate[2])\n",
    "        # print(url)\n",
    "        urlList.append(url)\n",
    "        \n",
    "    headlines = []\n",
    "    for u in urlList:\n",
    "        headL = captureHeadlines(u)\n",
    "        headlines.append(headL)\n",
    "        \n",
    "    return headlines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[[{'Title': 'State will protect interests of indigenous Assamese: CM ...',\n   'Publisher': 'Hindustan Times',\n   'Link': 'https://www.hindustantimes.com/india-news/state-will-protect-interests-of-indigenous-assamese-cm-sonowal/story-AihOP553yuiXincJwEViJP.html'},\n  {'Title': 'Opposition orchestrated anti-CAA protests by misleading the ...',\n   'Publisher': 'Hindustan Times',\n   'Link': 'https://www.hindustantimes.com/india-news/opposition-orchestrated-anti-caa-protests-by-misleading-the-people-says-naqvi/story-eLINeCFDFGZLZrkxMq9OgI.html'}]]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "getHeadlines(query, start, end)\n",
    "# # storing data in JSON format\n",
    "# import json\n",
    "# with open('articles.json', 'w', encoding='utf-8') as file:\n",
    "#     line = json.dumps(content) + '\\n'\n",
    "#     file.write(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# print(content)\n",
    "# table = pd.DataFrame.from_dict(content, orient='index')\n",
    "# table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}